\documentclass[main.tex]{subfiles}


\begin{document}
 \section{Perception}
 \subsection{Main Perception packages}
 Create a new workspace or open the workspace where you want to install the Perception part. If you are using the same workspaces we do, use the suturo\_ws workspace.

 Now install the rs\_addons dependencies by running the following commands.
 \begin{lstlisting}
sudo add-apt-repository ppa:robosherlock/ppa
sudo apt-get update
sudo apt-get install rapidjson 
\end{lstlisting} 
 
  Then run the following commands to download dependencies and the Perception part into your workspace. If you want to install Caffe, it is important to run "catkin build" \textbf{after} Caffe was successfully installed.
 
 \begin{lstlisting}
cd src
git clone %*\url{https://github.com/SUTURO/suturo_perception.git}*)
git clone %*\url{https://github.com/SUTURO/suturo_resources.git}*) 
git clone %*\url{https://github.com/evankapi/rs_hsrb_perception.git}*) -\b suturo20
git clone %*\url{https://github.com/RoboSherlock/robosherlock.git}*) --\recursive
cd robosherlock
git checkout eda6b38ecc6df7dbe9c12cb02af314729a66a9ef
cd ..
git clone %*\url{https://github.com/RoboSherlock/rs_resources.git}*)
git clone %*\url{https://github.com/Jastock/rs_addons.git}*)
rosdep install --from-path . --ignore-src -r 
cd ..
catkin build
\end{lstlisting}
 
 
\subsection{Caffe}
To install Caffe, use the following commands.
 \begin{lstlisting}
sudo apt-get update
sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-\dev libopencv-dev libhdf5-serial-dev protobuf-compiler
sudo apt-get install --no-install-recommends libboost-all-dev
sudo apt-get install libgflags-dev
sudo apt-get install libgoogle-glog-dev
sudo apt-get install libopenblas-dev
sudo apt-get install liblmdb-dev
cd 
git clone %*\url{https://github.com/BVLC/caffe.git}*)
\end{lstlisting}
 
 For GPU acceleration install \href{https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#ubuntu-installation}{CUDA}, a graphics card driver update may be necessary for this to work.
 
 Installation with CMake:\\
 
 Change into your caffe directory and open up the CMakeLists.txt in your editor. After the comment labeled "Options" you can set options for your build. If you installed CUDA and want GPU acceleration set CPU\_ONLY to OFF, otherwise set it to on ON.
 
 Now enter your cmake directory and open up the Dependencies.cmake file. Go to the comment labeled "BLAS" and in the line under 
 
 \begin{lstlisting}
 if(NOT APPLE)
\end{lstlisting}
 
 change it to 
 
 \begin{lstlisting}
 set(BLAS "Open" CACHE STRING "Selected BLAS library")
\end{lstlisting}
 
 Exit the file and from your cmake directory run the following commands:
 \begin{lstlisting}
 cmake ..
 make all
 make install
 make runtest
\end{lstlisting}

\newpage
 
 
 
 
Installation with make:

The installation with cmake is highly recommended, but if this should not work, the following is the alternative.

 Make following changes to the Caffe directory : \\

Copy the Makefile.config.example with 
\begin{lstlisting}
cp Makefile.config.example Makefile.config
\end{lstlisting}
Make the following changes on the Makefile.config :\\

If CUDA is not installed uncomment CPU\_ONLY := 1 to enable building for CPU only.\\
Change "BLAS := atlas" to "BLAS := open"\\
If any hdf5 related erros appear in the next step, add 
\begin{lstlisting}
/usr/lib/x86_64-linux-gnu/hdf5/serial
\end{lstlisting}
 to LIBRARY\_DIRS and
\begin{lstlisting} 
  /usr/include/hdf5/serial/ 
\end{lstlisting} 
  to INCLUDE\_DIRS.\\
Now save and exit.

 	
Now you need to build caffe using the following commands.
\begin{lstlisting}
make all
make test
make runtest  
\end{lstlisting}

\subsection{Further steps after downloading the packages, dependecies and installing Caffe}


If all the tests are successfull, you can now build your workspace using
\begin{lstlisting}
catkin build
\end{lstlisting}

To be able to use Caffe, you now need to download a trained model file, or train your own network. To download the "bvlc\_reference\_caffenet", which was used in the SUTURO project, change to the "scripts" directory in your caffe directory. You can now download the trained model by executing

\begin{lstlisting}
./download_model_binary.py ../models/bvlc_reference_caffenet/
\end{lstlisting}



For information on how to do feature extraction with Caffe see \ref{feature_extraction}, information on how to classify with the rs\_addons package and Caffe can be found at \ref{classifying}. 

\subsection{Feature Extraction} \label{feature_extraction}
\subsubsection{Setup}
To set everything up for feature extraction with the BVLC Reference Caffenet, you have to perform the following steps:

Copy the the bvlc\_reference\_caffenet.caffemodel modelfile from 
\begin{lstlisting}
your_caffe_directory}/models/bvlc_reference_caffenet
\end{lstlisting}

 to
 
\begin{lstlisting}
your_rs_resources_directory/caffe/models/bvlc_reference_caffenet
\end{lstlisting}

Copy the folders with your training data to 

\begin{lstlisting}
your_rs_resources_directory}/objects_dataset/object_data
\end{lstlisting}
As training data you could for example use images from the odu\_iai repository\footnote{\url{https://github.com/bbferka/odu_iai}}. As a minimal example you could take two directories out of the \linebreak odu\_iai/object/data/partial\_views directory.\\

Now, use the bash scripts described in the \textit{Feature Extraction Tools} chapter of the SUTURO projects final report to generate a split file and a classlist file. This gives the feature extractor the information to map the extracted features of your images to their classes.
After that, create a directory to hold your extracted features.

\subsubsection{Extraction}
Now you can just run in a terminal, with the workspace in which you installed the perception packages sourced:

\begin{lstlisting}
rosrun rs_addons featureExtractor -s your_split_file -f BVLC_REF -o your_extracted_features_directory
\end{lstlisting}

This will extract the features in your specified directory. If you want some information about the featureExtractor you can run

\begin{lstlisting}
rosrun rs_addons featureExtractor -h
\end{lstlisting}

\subsection{Classifying} \label{classifying}
\subsubsection{KNN}

Now that you have extracted features from some images, you can use these features to classify. To do this, you first copy the data file and the ClassLabel file from your extracted features directory to 

\begin{lstlisting}
your_rs_resources_directory/extracted_feats
\end{lstlisting}

After that you open the KnnAnnotator.yaml file in
\begin{lstlisting}
your_rs_addons_directory/descriptors/annotators
\end{lstlisting}
 
Here, you set the feature\_descriptor\_type to BVLC\_REF. After that you set class\_label\_mapping to

\begin{lstlisting}
extracted_feats/name_of_your_ClassLabel_txt
\end{lstlisting}

and you also set training\_data to


\begin{lstlisting}
extracted_feats/your_data_yaml
\end{lstlisting}

For default\_k you have to find the k that works best for your application. To find the best k, you can use the clusterLabeling package described in the SUTURO projects final report to compare different k's. To start, a k of 11 or 13 works well. After saving and closing, you can add the CaffeAnnotator and the KnnAnnotator at the end of your RoboSherlock pipeline in this order, or just use the hsrb\_1ms pipeline from the rs\_preception package. Run the pipeline by executing
\begin{lstlisting}
rosrun robosherlock run _ae:=your_pipeline_name _vis:=true
\end{lstlisting}

You should now be able to see a classification in the viewer of the KnnAnnotator. You can switch the viewers for the different annotator while having the Image Viewer window selected, with the n and p keys on the keyboard.

 
\subsubsection{Other Classifiers}
If you want to use other classifiers, like Random Forest or SVM, which are both implemented in rs\_addons, you have to train them on your extracted features using the train\_classifer executable from the rs\_addons package.\\

You do this by running 

\begin{lstlisting}
rosrun rs_addons train_classifier -c SVM -i your_data_yaml -l your_label_txt
\end{lstlisting}

You can change the parameter -c from SVM to RF, if you want to train Random Forest. Running this will output a file called classifer.xml holding the trained data to 
\begin{lstlisting}
your_rs_addons_directory/trainedData
\end{lstlisting}

To use it, you have to open up the SvmAnnotator.yaml or the RfAnnotator.yaml in

\begin{lstlisting}
your_rs_addons_directory/descriptors/annotators
\end{lstlisting}

You then set actual\_class\_label to your ClassLabel .txt file and trained\_model\_name to the name of the file from train\_classifer. The annotators always look for this file in the

\begin{lstlisting}
your_rs_addons_directory/trainedData
\end{lstlisting}

directory. Now you just swap out the KnnAnnotator for the SvmAnnotator or the RfAnnotator in your pipeline and they should classify.

 

\end{document}
