\documentclass[main.tex]{subfiles}
\begin{document}
	
	\chapter{Knowledge}
		\chapterauthor{Merete Bommarius, Paul Schnipper}
		\section{Natural Language Processing}
		Natural Language Processing,NLP for short, describes the application of computational techniuqes to the analysis and synthesis of natural language and speech. It is currently used in the field of linguistics, computer science, information engineering and artificial intelligence (AI). Challenges with natural language processing involve the speech recognition itself, natural language understanding and the natural language generation.\\
		The first challenge was to figure out whether shallow or deep semantic parsing should be used. Shallow semantic parsing is solely used for identifying entities in an utternace and labelling them with the roles they play. Therefore it is sometimes also referred to as slot-filling or frame semantic parsing. Deep semantic parsing on the other hand is concerned with producing precise representations of utterances that can contain significant compositionality. It is because of that also known as compositional semantic parsing.\\
		As the name suggests, deep semantic parsing goes a lot more into detail when it comes to the parsing itself, but for our situation it would make the endresult a lot more unreliable since it would only lead to confusion for the robot. So, it was decided to use shallow semantic parsing instead.
		\subsection{Parsing}
		As mentioned previously, shallow semantic parsing is used to parse and frame the commands that the robot will receive. The one that the group initially wanted to used is named open-sesame but is currently unavailable since it is being updated and rewritten to work with Python3. Instead we use a parser called Sling. It is not as good as open-sesame would have been, which is why it needs training.\\
		At the moment the parsing for the sentence looks like this:
		\begin{equation}
		\{‘predicate’: ‘take’\} \{‘ARG1’: ‘cup’\} \{‘ARG2’: ‘table’\}
		\end{equation}		
		The sentence used as an example for this was: ‘take the cup to the table‘.
		\subsubsection{Training the Parser}
		In order to really be able to train the parser there are a few requirements that need to be met. First, there must be a corpus which the training program can use as a reference. This corpus should contain 50.000+ sentences. The solution that was used in order to get to this number was writing about 120 sentences and annotate them. Annotating helps setting the guidelines for the grammar that was used to set guidelines for the random sentence generator that was used to provide us with the required numbers of sentences.\\
		The grammar that was written looks for example like this:
		\begin{equation}
		MovementOnly \rightarrow [Source]Direction[Destination][Destinationdepictive^*]][Manner^*]
		\end{equation}		
		This describes the ‘MovementOnly‘ action. With this action, they primarily use their motion rather than their visual sense. This action contains simple movements like moving from a source to a destination or simply into a given direction.
		As you can see, the grammar starts off with a term which is then explained in further detail. It also provides a structure that is to be used for the sentence, which is later being randomly generated.The training of the parser itself is still ongoing since it takes multiple days or even weeks, depending on how thorough you want the result to be.
	
\end{document}