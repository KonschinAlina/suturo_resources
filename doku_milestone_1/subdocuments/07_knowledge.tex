\documentclass[main.tex]{subfiles}
\begin{document}
	
	\chapter{Knowledge}
		\chapterauthor{Merete Bommarius, Paul Schnipper}
		\section{Knowledge}
		The knowledge group was attempting to mainly reuse the knowledge base developed by the Suturo18/19 team. Sadly because of problems with KnowRob knowledge didn't focus on the problem at hand.\\
		Currently we are only able to add objects with the following attributes to the knowledge base:\\
		\begin{itemize}
			\item Size: width, height, depth
			\item Position relative to the map in the tf-tree
			\item orientation in 3D space
			\item color
			\item type (we haven't defined our own objects in the ontology yet)
		\end{itemize}
		
		
	
		\section{Natural Language Processing}
		Natural Language Processing,NLP for short, describes the application of computational techniuqes to the analysis and synthesis of natural language and speech. It is currently used in the field of linguistics, computer science, information engineering and artificial intelligence (AI). Challenges with natural language processing involve the speech recognition itself, natural language understanding and the natural language generation.\\
		The first challenge was to figure out whether shallow or deep semantic parsing should be used. Shallow semantic parsing is solely used for identifying entities in an utterance and labelling them with the roles they play. Therefore it is sometimes also referred to as slot-filling or frame semantic parsing. Deep semantic parsing on the other hand is concerned with producing precise representations of utterances that can contain significant compositionality. It is because of that also known as compositional semantic parsing.\\
		As the name suggests, deep semantic parsing goes a lot more into detail when it comes to the parsing itself, but for our situation it would make the endresult a lot more unreliable since it would only lead to confusion for the robot. So, it was decided to use shallow semantic parsing instead.
		
		
		\subsection{Parsing}
		As mentioned previously, shallow semantic parsing is used to parse and frame the commands that the robot will receive. The one parser that the group initially wanted to used is named open-sesame but is currently unavailable since it is being updated and rewritten to work with Python3. Instead we use a parser called Sling. It is not as good as open-sesame would have been, which is why it needs training.\\
		At the moment the parsing for the sentence looks like this:
		\begin{equation}
		\{‘predicate’: ‘take’\} \{‘ARG1’: ‘cup’\} \{‘ARG2’: ‘table’\}
		\end{equation}		
		The sentence used as an example for this was: ‘take the cup to the table‘.
		
		\subsubsection{Training the Parser}
		In order to really be able to train the parser there are a few requirements that need to be met. First, there must be a corpus which the training program can use as a reference. This corpus should contain 50.000+ sentences. The solution that was used in order to get to this number was writing about 120 sentences and annotate them by hand. Annotating helps setting the guidelines for the grammar that was used to set guidelines for the random sentence generator that was used to provide us with the required numbers of sentences.\\
		The grammar that was written looks for example like this:
		\begin{equation}
		MovementOnly \rightarrow [Source]Direction[Destination][Destinationdepictive^*]][Manner^*]
		\end{equation}		
		This describes the ‘MovementOnly‘ action. With this action, they primarily use their motion rather than their visual sense. This action contains simple movements like moving from a source to a destination or simply into a given direction.
		As you can see, the grammar starts off with a term which is then explained in further detail. It also provides a structure that is to be used for the sentence, which is later being randomly generated. The training of the parser itself is still ongoing since it takes multiple days or even weeks, depending on how thorough you want the result to be.
		
		\subsubsection{Parsing Text in ROS}
		To use parse the text we decided to use Google Sling. Sling is a tensorflow powered semantic parser. The Python Sling API sadly only supports Python versions 3+. Because of that we had to find a way to bridge the gap between a ROS node, Python 2.7, and Sling.\\
		The solution was to create a ROS node which performs a system subprocess call to start a separate python3 script. This script simply starts a TinyRPC server. RPC stands for remote procedure call, this allows one program to provide a function for a different program, even over different programming languages and over multiple systems. The ROS node takes a string from a simple message, calls the Sling API via TinyRPC and gets a String as return variable. This gets published as a String again.
		
		\subsection{Speech to Text}
		We are currently using the python SpeechRecognition library. This library supports online and offline speech recognizers. Sadly the only free only recognizer is provided by Google, but even that is limited to one hour of speech per day. 
		It appears the only option is to use julius speech recognition, sadly this recognizer is not supported by the SpeechRecognition library and we weren't able to load 'real' dictionaries to actually try the recognition.
\end{document}
