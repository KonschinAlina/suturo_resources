\documentclass[main.tex]{subfiles}
\begin{document}
	
	\chapter{Distribution of Tasks}
		\chapterauthor{Merete Bommarius}

		\section{Planning:}
		The task that Planning is focusing on that the moment is the integration of the interfaces and communication from and between the different groups. The group is also responsible for the errorhandling, which means that they act as a middle-man between groups in order to gain access to all sides, which makes it easier to identify and correct possible errors.
		
		\section{Perception:}
		The goal for the Perception group is to perceive, and identify objects in a given location, which in our case is a table. They also have to differenciate between objects if it the same one with just slight differences, for example the color. After Perception identifies the object, they  will extract the information and forward it for further processing. For this, they are triggered by planning and communicate furthermore with Knowledge.
		
		\section{Manipulation:}
		Manipulation‘s job was it to create actionservers to incorporate the different physical actions that the HSR can take; grabbing, putting down, and knocking over varies objects. Every one of those action have to be doable with the gripper attached to the robot.Navigation:Navigation works closely together with Manipulaton. While Manipulation works on the physical actions that can be performed with the gripper, Navigation focuses on the HSR‘s movements. Here, they pay special attention to the robot‘s surroundings and make sure there is an anti-collision server in place to aviod collision with any objects.
		
		\section{Knowledge:}
		The Knowledgebase has been implemented rather early on in this Milestone, it being one of the highest priorities. We still need to implement a few things but those are minor, and the Knowledge part of the SUTURO project will be able to be showcased in the second Milestone. 
		
		\section{NLP:}
		Albeit this part of the project has not been fully included in the robot yet, there has been progress. There are commands which start and stop the current task the robot is doing, being "Robot start" and "Robot stop". Currently there are still some changes that need to be made to make this feature fully functional. NLP is also focusing on readying the output that the HSR is supposed to give in certain situations. An Elaboration on this topic follows later in the NLP section of the documentation.  
\end{document}
