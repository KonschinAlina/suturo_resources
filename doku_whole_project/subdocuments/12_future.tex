\documentclass[main.tex]{subfiles}

\begin{document}

	\begingroup

	\renewcommand{\cleardoublepage}{}

	\renewcommand{\clearpage}{}

	\chapter{Ideas and recommendations for the future}
		
		\section{In general}
				\chapterauthor{}
		Here comes a compact conclusion about what decisions were or were not good and should or should not be done the same way in the future.
		
		\section{Specific features}
		Here comes a list and an explanation of different features that would be nice to implement even though we didn't have the time to implement them ourselves in the end.
		
		% Planning:
		
		
		% Perception:
		\subsection{Perception: Compute grasp pose}
		\chapterauthor{Evan Kapitzke}
		The estimation of the grasping pose could be done with RoboSherlock. Based on the depth camera image we would calculate a few possible grasping points, which then could be used by Manipulation to optimize their grasping procedure. The depth camera images are only available while Perception processes them. The calculation should be implemented in an additional annotator and some modifications to the process manager.
		
		\subsection{Perception: Comparing classifiers}
		\chapterauthor{Jan-Frederik Stock}
		With the clusterLabeling package, it is now possible to quantify classification performance and thus compare different classifiers. To achieve a 					representative result, a couple of different scenes with different objects should be recorded, with the objects not overlapping. It is crucial to get a
		good clustering for the scenes, so point cloud filtering should be used to achieve this. Now, the scenes have to be labeled, the more frames the better. 
		When this is done, the different classifiers can be tested with the classificationEvaluationAnnotator. It is very important to not change anything but 
		the classifier in the pipeline, so the results do not get distorted.
		
		
		% Knowledge:
		\subsection{Knowledge: Continue optimizing the object goal pose}
		\chapterauthor{Jeremias Thun}
		The decision about where to put the object works for some scenarios very well but it can have some problems depending on the order in which the objects are grasped. One of the biggest problems is: As described in section \ref{sec:kn_pickup}, the objects  similar to one of the already placed objects are put into a list, which is then cut to only place those most similar to the reference object. If we were for example placing three bananas next to two apples where there only enough space for one more object, Knowledge would recognize that the bananas need to open a new group and cut the last two bananas out. But to keep it simple, we ignore those two bananas at the time - which leads to a situation in which Knowledge would place the first banana next to the two apples and only starting a new group for the bananas when it is looking for a place for the second and third banana.
	  	
	  	\subsection{Knowledge: Optimize next\_object/1}
	  	\chapterauthor{Jeremias Thun}
	  	The decision which object should be the next one to grasp is still very rudimentary. The responsible predicate \texttt{next\_object/1} in \texttt{pickup.pl} just looks for the nearest object right now (as described in section \ref{sec:kn_pickup}).\\
	  	While that is a good start, it would be nice to mind some other criteria.
	  	
	  	Based on the new object placing strategy it would be pretty nice to weigh in which object fits the best to it's reference object. Especially when you expect to get more information during your run it can significantly improve the resulting order of the objects if the ones that will more likely be put next to their reference object would be taken earlier.
	  	
		On the other hand if the time is limited and your most important goal is to get at least some of the recognized objects in their final place (this is pretty much the RoboCup scenario), it can be a good idea to take those objects first, that perception was most confident about. This way, if you fail to place all the objects before the time runs out, you will have at least placed the ones you did with a higher confidence. This is a scenario, in which the idea to take the most similar objects first can be a good idea, too: That way, the few actually placed objects would be in an intuitively good order.
		
		If there are significant differences, you could also make some tests and see which objects are easier to grasp so you can take them first. But in our test series there were no significant differences in that matter. 
		
		With all these criteria the real challenge is to make them work with each other without having to use a machine learning algorithm. A nice approach could be for example, to first look for the distance to the robot, define a threshold within wich the physical distance doesn't make a real difference, look for other objects with the same distance to the robot plus this threshold and sort them by one or two of the other criteria. 
		
		\subsection{Knowledge: Unit Tests}
		\chapterauthor{Jeremias Thun}
		Knowledge is not that easy to test in an integrated system. To really test all it's potential, you would need all the other groups to have fully functional versions of their code and you will need quite some time to watch the robot move itself and the objects just to know if the nth object is placed correctly.\\
		That is why especially Knowledge can really profit from some Unit Testing.
		
		We already started working on some unit tests for our code, but sadly we never got to actually have tests at a level that they can help us find bugs. To write and execute those Tests, \texttt{rosprolog} thankfully provides a special ROS Script, documented in the readme of \texttt{rosprolog}.

		% NLP

		
		% Manipulation
		
		
		% Navigation
		
		
	\endgroup

\end{document}
