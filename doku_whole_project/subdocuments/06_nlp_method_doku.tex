\documentclass[main.tex]{subfiles}

\begin{document}

	\begingroup

	\renewcommand{\cleardoublepage}{}

	\renewcommand{\clearpage}{}
	
	\newpage

	\chapter{NLP Function Documentation}
		\chapterauthor{Merete Bommarius, Paul Schnipper}
		
		
	\begin{tabular}{|l|p{9cm}|}
		\hline
		\textbf{Package} & \textbf{Features/Purpose} \\
		\hline
		suturo\_julius & Provides speechrecognition features. Uses HSR included julius speechrecognizer. \\
		\hline 
		suturo\_textparser & Parses input created by julius. Does static and dynamic, sling based, text analysis. \\
		\hline
		suturo\_nlg & Performs natural language generation. Also contains the knowledge interface. \\
		\hline 
		suturo\_speechparser & Contains ros-lauchfiles spanning all of the above packages.\\
		\hline
	\end{tabular}
	
	\section{The suturo\_julius Package}
	\chapterauthor{Paul Schnipper}
		\subsection{About Julius}
			Julius is a continuous speech recognition software. It is released under BSD-3 license by the Kyoto University. Toyota created a ROS-wrapper for Julius, it is published a part of the \texttt{ros-kinetic-hsrb-full} apt-get-Package.\\
			In theory the Julius engine supports a lot of different languages, but currently there are only two speech models
			Julius works on dictionaries. Dictionaries are a customizable way of providing the speech recognizer with words or sentences to recognize.
		\subsection{how dictionaries work}
			Dictionaries can be either word-based or grammar-based. Dew to word-based dictionaries only producing single-word output and grammar-based dictionaries being capable of whole-sentence recognition, the SUTURO-Project uses grammar-based dictionaries.
		
		\subsubsection{word-based dictionary}
			For testing purposes we created one word-based dictionaries. It can be found in \lstinline|/suturo_julius/dictionaries/examples/word|.\\
			This contains the \texttt{word\_sample} file.\\
			\begin{lstlisting}
				shelf sh eh l f
				table t ey b ax l
				milk m ih l k
				chocolate ch ao k l ax t
				robot	r ow b ow t
				chips	ch ih p s
				a	ah
				vase	w ah z\end{lstlisting}
			The file just contains words and their phonetic representation in a single line seperated by a single space.
			
		\subsubsection{grammar-based dictionaries}
			Grammar-based dictionaries consist of two editable files. The \texttt{.grammar} and \texttt{.voca} file.\\
			The \texttt{.grammar} file describe how sentences are build. Sentences are build in a Backus–Naur form grammar.\\
			\begin{lstlisting}
				S : NS_B COMMANDS NS_E
				COMMANDS : COMMAND
				COMMANDS : COMMAND and COMMAND
				COMMAND : move to the LOCATION
				COMMAND : grasp the ITEM
				LOCATION : couch table
				LOCATION : table
				LOCATION : shelf
				ITEM : Beer can
				ITEM : Coke
				ITEM : Marmelade
				ITEM : Cookies
			\end{lstlisting}
			Every symbol is nonterminal, except for symbols defined in the \texttt{.voca} file. Terminals are defined as a word category. The category is defined through \newline \lstinline{% <<name>>}
			In the \texttt{.voca} file the word and the the phonetic representation are separated by a space.
			\begin{lstlisting}
				% and
				and ae n d
				% move
				move m uw v
				% to
				to t uw
				to t ih
				% the
				the dh ax
				% grasp
				grasp g r ae s p
				% couch
				couch k aw ch
				% table
				table t ey b ax l
				% shelf
				shelf sh eh l f
				% Beer
				Beer b ih r
				% can
				can k ae n
				% Coke
				Coke k ow k
				% Marmelade
				Marmelade m aa r m ax l ey d
				% Cookies
				Cookies k uh k ix
				Oreos ao r iy ow s
			\end{lstlisting}
		Grammars have to be compiled to run. To compile run \texttt{rosrun tmc\_julius mkdfa.pl <<grammar\_name>>} e.g. \texttt{rosrun tmc\_julius mkdfa.pl grammar}. Both the \texttt{.grammar} and \texttt{.voca} file have to be named identical. E.g. \texttt{grammar.grammar} and \texttt{grammar.voca}. The compiler creates the \texttt{.dfa}, \texttt{dict} and \texttt{.term} files.	
		
		\subsection{The Suturo Dictionaries}
		The suturo\_julius package contains 3 different grammar-based dictionaries. hard\_commands contains sentences telling the robot to start, stop or continue the task.
		soft\_commands describes commands the robot may execute in the RoboCup. This dictionary contains sentences like: Fetch the cup from the table.Or: Find me some chocolate.
		\subsection{Configuration files}
		The \texttt{julius\_conf} folder contains one \texttt{.jconf} file. The context of the file has been taken from the \texttt{tmc\_julius} package.
		\subsection{Launchfiles}
		The \texttt{suturo\_julius} package provides four different launch files.\\
		\begin{itemize}
			\item julius\_qa\_system.launch:
			\subitem Launching Julius just with the grammar for the QA-system.
			\item speech\_recognition\_grammar.launch:
			\subitem Launching Julius with the grammars for hard commands and for dynamic commands.
			\item speech\_recognition\_hard\_commands.launch:
			\subitem Launching Julius just with the grammar for the hard commands.
			\item speech\_recognition\_word.launch:
			\subitem An example for how Julius is launched with a word based dictionary.
		\end{itemize}
	\section{The suturo\_textparser Package}
	\chapterauthor{Paul Schnipper}
		\subsection{textparser.py}
		The textparser node is designed to take in the output from Julius and check if the output is a hard command or send it to the Sling-Parser.
		\subsubsection{callback(data)}
		The \texttt{callback} function is called with the data published by Julius. Julius publishes its output in the \texttt{tmc\_rosjulius\_msgs.msg.RecognitionResult} message type. The \texttt{callback} function calls the \texttt{find\_first} function to get a String representing the recognized sentence. It is then checked if the String is a static command. To do that the \texttt{is\_static} command is called.
		
		\subsubsection{find\_first(data)}
		The \texttt{find\_first} function takes the data published by Julius and checks weather the recognition confidence is high enough. If so it returns the recognized sentence as String, if the confidence is not high enough the function returns an empty string.\\
        
        \subsubsection{is\_static(sentence)}
        The \texttt{is\_static} command calls the \texttt{is\_stop}, \texttt{is\_start} and \texttt{is\_continue} functions. If the sentence is one of these hard command types the function publishes the command type on the \texttt{'hard\_commands'} topic.
        
		\subsubsection{is\_stop, is\_start and is\_continue}
        These functions check weather a string is a hard command of the type \texttt{STOP, START or CONTINUE} respectively. To perform this check the \texttt{is\_in\_file} function is called. The text files containing the hard commands can be found in the \texttt{commands} folder.
        
        \subsubsection{is\_in\_file}
        This function checks if a string is identical to a single line in a text file.
        
		\subsection{slingparserRosInterface.py \& slingparser.py3}     	
        \subsubsection{Basics of Frame Semantics \small{\textit{Merete Bommarius}}}        
        Frame semantics is a theory of linguistic meaning, developed by Charles J. Fillmore. It extends his earlier case, grammar and relates linguistic semantics to encyclopedic knowledge. The theory applies the notion of a semantic frame, which is also used in AI. A semantic frame can also be defined as a coherent structure of related concepts. The frames themselves are based on recurring human experiences.\\
        Frame semantics are used to give the parser a sense of structure. The way the group approached this was by framing about 100 commands by hand and then used those annotated sentences as examples of how the parser should interprete sentences that might be similar but are not in the list of commands. 
        Here is an example of an annotated sentence: 
        
        \texttt{ [bring]$_{action}$  [me]$_{beneficiary}$ [the pills]$_{item}$ from [the shelf]$_{source}.$}
        \subsubsection{Parsing \small{\textit{Merete Bommarius}}}     
        As mentioned previously, shallow semantic parsing is used to parse and frame the commands that the robot will receive. The one that the group initially wanted to used is named open-sesame but is currently unavailable since it is being updated and rewritten to work with Python3. Instead we use a parser called Sling. It is not as good as open-sesame would have been, which is why it needs training.\\ 
        In the first Milestone, the parsing for the sentence looks like this:
        
        \begin{verbatim}
        {‘predicate’: ‘take’} {‘ARG1’: ‘cup’} {‘ARG2’: ‘table’}
        \end{verbatim}
        
        The sentence used as an example for this was: ‘take the cup to the table‘. After training the parser, the annotation for the sentence would look more like:
        
        \begin{verbatim}
        {‘predicate’: ‘take’} {‘object’: ‘cup’} {‘destination’: ‘table’}
        \end{verbatim}
        
		\subsubsection{About SLING}
        SLING is a natural language frame semantic parser developed by Google. It is published under the Apache License 2.0. SLING is  
		\subsubsection{About TinyRPC}
		\subsubsection{slingparserRosInterface.py}
		\subsubsection{slingparser.py3}
			
	
	\section{The suturo\_nlg Package}
	    \chapterauthor{Paul Schnipper}
		\subsection{nlg\_ros.py \& nlg.py3}
		\subsection{demo\_answers\_ros.py \& demo\_answers.py3}
		\subsection{knowledge\_interface.py}
			
	\section{The suturo\_speechparser Package}
	    \chapterauthor{Paul Schnipper}	
		
        
        


	
	\section{Frame Semantics}
	 	\chapterauthor{Merete Bommarius}
	Frame semantics is a theory of linguistic meaning, developed by Charles J. Fillmore. It extends his earlier case, grammar and relates linguistic semantics to encyclopedic knowledge. The theory applies the notion of a semantic frame, which is also used in AI. A semantic frame can also be defined as a coherent structure of related concepts. The frames themselves are based on recurring human experiences.\\
	As mentioned in the previous section, frame semantics are used to give the parser a sense of structure. The way the group approached this was by framing about 100 commands by hand and then used those annotated sentences as examples of how the parser should interpret sentences that might be similar but are not in the list of commands. 
	Here is an example of an annotated sentence: 

	\texttt{ [bring]$_{action}$  [me]$_{beneficiary}$ [the pills]$_{item}$ [from the shelf]$_{source}.$}
	
	
	
	\section{Training the Parser}
	 	\chapterauthor{Merete Bommarius}
	In order to really be able to train the parser there are a few requirements that need to be met. First, there must be a corpus which the training program can use as a reference. This corpus should contain 50.000+ sentences. The solution that was used in order to get to this number was writing about 120 sentences and annotate them. Annotating helps setting the guidelines for the grammar that was used to set guidelines for the random sentence generator that was used to provide us with the required numbers of sentences.
	The grammar that was written looks for example like this:

		
		\texttt{MovementOnly\\
		MovementOnly $\rightarrow$ take ITEM [from SOURCE] [to DESTINATION] [MANNER]\\
		MovementOnly $\rightarrow$ bring [BENEFICIARY] ITEM [from SOURCE]\\}
		
		\texttt{This describes the 'MovementOnly' action.
		With this action, they primarily use their motion rather than their visual sense. This action contains simple movements like moving from a source to a\\ destination or simply into a given direction.}
		



	As you can see, the grammar starts off with a term which is then explained in further detail. It also provides a structure that is to be used for the sentence, which is later being randomly generated.\\ 
	Depending on how thoroughly the training of the parser is supposed to be, it might take a few days up till a few weeks, and the parser needs to be retrained if new information or commands are added.

	\section{Generated Speech}
	 	\chapterauthor{Merete Bommarius}
	The output the robot can give if it was given a task is split into six different sections. These sections are called; reject, task, waiting, failed, finished, and complications. Reject describes the decision the robot makes to deny the task, while task described the decision to perform it. Waiting and failed are similar. While waiting describes the robot waiting to understand the 
	given task, failed describes that the robot has failed to understand. Finished means that the robot has finished performing the given task and complications describe, as the name says, complications that can occur during the performance of the task.\\ 
	Outcomes for the different sections can for example be:
			
	\begin{verbatim}
	Reject = "Get someone else." or "Me is too superior for task."
	Task = "Yes, Human." or "Me got Human covered."
	Waiting = "Calibrating." or "Please wait."
	Failed = "Please speak loud and clear." or "Please repeat."
	Finished = "Mischief managed." or "Task completed."
	Complications = "Humans are too tall, Me cannot see." or "Object is too small."
	\end{verbatim}
	
	The reject section is solely for laughs and giggles. The robot will still perform the task.
	
\end{document}
