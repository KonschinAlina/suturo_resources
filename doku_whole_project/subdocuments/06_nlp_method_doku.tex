\documentclass[main.tex]{subfiles}

\begin{document}
\renewcommand{\cleardoublepage}{}   
\renewcommand{\clearpage}{}
\newpage

\chapter{NLP Function Documentation}
\chapterauthor{Merete Bommarius, Paul Schnipper}


\section{About Natural Language Processing}
\chapterauthor{Merete Bommarius}
    Natural language processing, short; NLP, describes the application of computational techniques to the analysis and synthesis of natural language and speech. Challenges with natural language processing involve the speech recognition itself, natural language processing and the natural language generation, all of which are import in the context of the RoboCup@Home competition.\\ 
    The first challenge was to figure out whether shallow or deep semantic parsing should be used. Shallow semantic parsing is solely used for identifying entities in an utterance and labelling them with the roles they play. Therefore it is sometimes also referred to as slot-filling or frame semantic parsing. Roles are the identifying label that is put on a word or phrase to determine it‘s purpose in the sentence. If there for example is a command like: “Put the cup on the table“, the phrase “the table“ would have the role of the goal, since it is the place that the cup ends up in.
Deep semantic parsing on the other hand is concerned with producing precise representations of utterances that can contain significant compositionality. It is because of that, that it is also known as compositional semantic parsing.\\ 
  As the name suggests, deep semantic parsing goes a lot more into detail when it comes to the parsing itself, but for our situation it would make the endresult a lot more unreliable. It would add a lot of information that isn‘t needed and therefore becomes unnecessary. So, it was decided to use shallow semantic parsing.\\
    
    To perform NLP related actions the SUTURO group created four different ROS-packages.

    \begin{tabular}{|l|p{9cm}|}
        \hline
        \textbf{Package} & \textbf{Features/Purpose} \\
        \hline
        suturo\_julius & Provides speechrecognition features. Uses HSR included julius speechrecognizer. \\
        \hline 
        suturo\_textparser & Parses input created by julius. Does static and dynamic, sling based, text analysis. \\
        \hline
        suturo\_nlg & Performs natural language generation. Also contains the knowledge interface. \\
        \hline 
        suturo\_speechparser & Contains ros-lauchfiles spanning all of the above packages.\\
        \hline
    \end{tabular}

\newpage
\section{The suturo\_julius Package}
\chapterauthor{Paul Schnipper}

    \subsection{About Julius}
      Julius is a continuous speech recognition software. It is released under BSD-3 license by the Kyoto University. Toyota created a ROS-wrapper for Julius, it is published a part of the \texttt{ros-kinetic-hsrb-full} apt-get-Package.\\
      In theory the Julius engine supports a lot of different languages, but currently there are only two speech models
     Julius works on dictionaries. Dictionaries are a customizable way of providing the speech recognizer with words or sentences to recognize.
    \subsection{how dictionaries work}
      Dictionaries can be either word-based or grammar-based. Dew to word-based dictionaries only producing single-word output and grammar-based dictionaries being capable of whole-sentence recognition, the SUTURO-Project uses grammar-based dictionaries.
    
        \subsubsection{word-based dictionary}
            For testing purposes we created one word-based dictionaries. It can be found in \lstinline|/suturo_julius/dictionaries/examples/word|.\\
            This contains the \texttt{word\_sample} file.\\
            \begin{lstlisting}
shelf sh eh l f
table t ey b ax l
milk m ih l k
chocolate ch ao k l ax t
robot	r ow b ow t
chips	ch ih p s
a	ah
vase	w ah z
            \end{lstlisting}
            The file just contains words and their phonetic representation in a single line seperated by a single space.
            
    \subsubsection{grammar-based dictionaries}
        Grammar-based dictionaries consist of two editable files. The \texttt{.grammar} and \texttt{.voca} file.\\
        The \texttt{.grammar} file describe how sentences are build. Sentences are build in a Backus–Naur form grammar.\\
        \begin{lstlisting}
S : NS_B COMMANDS NS_E
COMMANDS : COMMAND
COMMANDS : COMMAND and COMMAND
COMMAND : move to the LOCATION
COMMAND : grasp the ITEM
LOCATION : couch table
LOCATION : table
LOCATION : shelf
ITEM : Beer can
ITEM : Coke
ITEM : Marmelade
ITEM : Cookies
        \end{lstlisting}
        Every symbol is nonterminal, except for symbols defined in the \texttt{.voca} file. Terminals are defined as a word category. The category is defined through \newline \lstinline{% <<name>>}
        In the \texttt{.voca} file the word and the phonetic representation are separated by a space.
        \begin{lstlisting}
% and
and ae n d
% move
move m uw v
% to
to t uw
to t ih
% the
the dh ax
% grasp
grasp g r ae s p
% couch
couch k aw ch
% table
table t ey b ax l
% shelf
shelf sh eh l f
% Beer
Beer b ih r
% can
can k ae n
% Coke
Coke k ow k
% Marmelade
Marmelade m aa r m ax l ey d
% Cookies
Cookies k uh k ix
Oreos ao r iy ow s
        \end{lstlisting}
        
        Grammars have to be compiled to run. To compile run \texttt{rosrun tmc\_julius mkdfa.pl <<grammar\_name>>} e.g. \texttt{rosrun tmc\_julius mkdfa.pl grammar}. Both the \texttt{.grammar} and \texttt{.voca} file have to be named identical. E.g. \texttt{grammar.grammar} and \texttt{grammar.voca}. The compiler creates the \texttt{.dfa}, \texttt{dict} and \texttt{.term} files.	
    
    \subsection{The Suturo Dictionaries}
        The suturo\_julius package contains 3 different grammar-based dictionaries. hard\_commands contains sentences telling the robot to start, stop or continue the task.
        soft\_commands describes commands the robot may execute in the RoboCup. This dictionary contains sentences like: Fetch the cup from the table.Or: Find me some chocolate.
    \subsection{Configuration files}
        The \texttt{julius\_conf} folder contains one \texttt{.jconf} file. The context of this file has been taken from the \texttt{tmc\_julius} package. This part of the package has been created to possibly handle configurations for different computers and if possible experiment with the configuration to increase recognition accuracy.
    \subsection{Launchfiles}
        The \texttt{suturo\_julius} package provides four different launch files.\\
        \begin{itemize}
            \item julius\_qa\_system.launch:
            \subitem Launching Julius just with the grammar for the QA-system.
            \item speech\_recognition\_grammar.launch:
            \subitem Launching Julius with the grammars for hard commands and for dynamic commands.
            \item speech\_recognition\_hard\_commands.launch:
            \subitem Launching Julius just with the grammar for the hard commands.
            \item speech\_recognition\_word.launch:
            \subitem An example for how Julius is launched with a word based dictionary.
        \end{itemize}

\section{The suturo\_textparser Package}
\chapterauthor{Paul Schnipper}
    \subsection{textparser.py}
        The textparser node is designed to take in the output from Julius and check if the output is a hard command or send it to the Sling-Parser.
        \subsubsection{callback(data)}
            The \texttt{callback} function is called with the data published by Julius. Julius publishes its output in the \texttt{tmc\_rosjulius\_msgs.msg.RecognitionResult} message type. The \texttt{callback} function calls the \texttt{find\_first} function to get a String representing the recognized sentence. It is then checked if the String is a static command. To do that the \texttt{is\_static} command is called. If the recognized sentence is not a static command the sentence is published on the \texttt{/to\_slingparser} topic to be analysed by SLING.
    
        \subsubsection{find\_first(data)}
            The \texttt{find\_first} function takes the data published by Julius and checks weather the recognition confidence is high enough. If so it returns the recognized sentence as String, if the confidence is not high enough the function returns an empty string.\\
    
        \subsubsection{is\_static(sentence)}
            The \texttt{is\_static} command calls the \texttt{is\_stop}, \texttt{is\_start} and \texttt{is\_continue} functions. If the sentence is one of these hard command types the function publishes the command type on the \texttt{'hard\_commands'} topic.
    
        \subsubsection{is\_stop, is\_start and is\_continue}
            These functions check weather a string is a hard command of the type \texttt{STOP, START or CONTINUE} respectively. To perform this check the \texttt{is\_in\_file} function is called. The text files containing the hard commands can be found in the \texttt{commands} folder.
    
        \subsubsection{is\_in\_file}
            This function checks if a string is identical to a single line in a text file.
    
    \subsection{slingparserRosInterface.py \& slingparser.py3}     	
        \subsubsection{Basics of Frame Semantics \small{\textit{Merete Bommarius}}}        
            Frame semantics is a theory of linguistic meaning, developed by Charles J. Fillmore. It extends his earlier case, grammar and relates linguistic semantics to encyclopedic knowledge. The theory applies the notion of a semantic frame, which is also used in AI. A semantic frame can also be defined as a coherent structure of related concepts. The frames themselves are based on recurring human experiences.\\
            Frame semantics are used to give the parser a sense of structure. The way the group approached this was by framing about 100 commands by hand and then used those annotated sentences as examples of how the parser should interprete sentences that might be similar but are not in the list of commands. 
            Here is an example of an annotated sentence: 
    
            \texttt{ [bring]$_{action}$  [me]$_{beneficiary}$ [the pills]$_{item}$ from [the shelf]$_{source}.$}
        \subsubsection{Parsing \small{\textit{Merete Bommarius}}}     
            As mentioned previously, shallow semantic parsing is used to parse and frame the commands that the robot will receive. The one that the group initially wanted to used is named open-sesame but is currently unavailable since it is being updated and rewritten to work with Python3. Instead we use a parser called Sling. It is not as good as open-sesame would have been, which is why it needs training.\\ 
            In the first Milestone, the parsing for the sentence looks like this:
    
\begin{lstlisting}
{'predicate': 'take'} {'ARG1': 'cup'} {'ARG2': 'table'}
\end{lstlisting}
            
            The sentence used as an example for this was: ‘take the cup to the table‘. After training the parser, the annotation for the sentence would look more like:
            
\begin{lstlisting}
{'predicate': 'take'} {'object': 'cup'} {'destination': 'table'}
\end{lstlisting}
            
        \subsubsection{Training the Parser \small{\textit{Merete Bommarius}}}
            In order to really be able to train the parser there are a few requirements that need to be met. First, there must be a corpus which the training program can use as a reference. This corpus should contain 50.000+ sentences. The solution that was used in order to get to this number was writing about 120 sentences and annotate them. Annotating helps setting the guidelines for the grammar that was used to set guidelines for the random sentence generator that was used to provide us with the required numbers of sentences.
            The grammar that was written looks for example like this:
            
            
\texttt{MovementOnly\\
                MovementOnly $\rightarrow$ take ITEM [from SOURCE] [to DESTINATION] [MANNER]\\
                MovementOnly $\rightarrow$ bring [BENEFICIARY] ITEM [from SOURCE]}
                
            \textit{This describes the 'MovementOnly' action.
                With this action, they primarily use their motion rather than their visual sense. This action contains simple movements like moving from a source to a\\ destination or simply into a given direction.}            
            As you can see, the grammar starts off with a term which is then explained in further detail. It also provides a structure that is to be used for the sentence, which is later being randomly generated.\\ 
            Depending on how thoroughly the training of the parser is supposed to be, it might take a few days up till a few weeks, and the parser needs to be retrained if new information or commands are added.
        
        \subsubsection{About SLING}
            SLING is a natural language frame semantic parser developed by Google. It is published under the Apache License 2.0.
        \subsubsection{About TinyRPC}
             remote procedure calls (RPC) are a way for one program to call functions provided by a different program. (In the background ROS is based on RPC technology as well.) tinyrpc is a framework for constructing remote procedure call RPC services in Python. Tiny-RPC implements the JSON-RPC protocol.\\
             TinyRPC is used to bridge the problem, that two powerful and necessary libraries, Sling and SimpleNLG (See The Suturo\_nlg Package) are only available for Python3.\\
             To solve this problem, the \texttt{slingparserRosInterface.py} starts \texttt{slingparser.py3} as a subprocess. The slingparser.py3 upon startup initializes the tinyRPC server and provides the \texttt{semantic\_parse()} function.
        \subsubsection[slingparserros]{slingparserRosInterface.py}
            The \texttt{slingparserRosInterface.py} subscribes to a topic on which \texttt{String} messages are published. It then calls the the semantic parse function provided by the \texttt{slingparser.py} script. This functions returns the annotated semantic frames in a python dictionary. This dictionary is then translated into a \texttt{MeaningRepresentation} message. This message definition contains an array of \texttt{KeyValuePair} messages. Each of these messages contains the frame as a key and the contents of the frame as the associated value.
        \subsubsection{slingparser.py3}
            The slingparser.py3 script wraps the Sling Semantic Parser. It currently loads a hard coded \texttt{flow} file.
            The \texttt{semantic\_parse} function actually calls the sling parser and takes its output and writes it into a dictionary to return.
    
\section{The suturo\_nlg Package}
\chapterauthor{Paul Schnipper}
    The \texttt{suturo\_nlg} package handles speech generation. But also contains the \texttt{knowledge\_interface} node, designed to answer simple questions by querying KnowRob through ROSProlog.
    \subsection{knowledge\_interface.py}
        The knowledge interface is designed to answer three different kinds of questions. Where is ITEM X supposed to go? What is on SURFACE? Is there a ITEM X on SURFACE?\\
        The \texttt{knowledge\_interface} subscribes to a topic using the \texttt{MeaningRepresentation} message. (See \hyperref[slingparserros]{slingparserRosInterface}) When there is a message published on this topic the \texttt{callback} function is called.
        \subsubsection{callback}
            The callback function takes the \texttt{MeaningRepresentation} message and converts it into a dictionary.
            Depending of what the predicate is one of the following functions is called.
            \begin{itemize}
                \item what\_is\_on
                \item supposed\_to\_go
                \item is\_there             
            \end{itemize}
    \subsection{demo\_answers\_ros.py \& demo\_answers.py3}
    
    
\section{The suturo\_speechparser Package}
    \chapterauthor{Paul Schnipper}
    This package contains three launchfiles created to launch nodes spreading the four previous packages.\\
    \begin{itemize}
        \item \texttt{hard\_commands\_only.launch}
            \subitem Starts Julius just with the dictionary for hard commands.
            \subitem And start a textparser node.
        \item \texttt{qa\_system.launch}
            \subitem Starts Julius with the dictionary for the QA-System.
            \subitem Starts a textparser node.
            \subitem Starts a slingparser node.
            \subitem Starts a knowledge\_interface node.
            \subitem And starts a demo\_answers node.        
        \item \texttt{speechparser.launch}
            \subitem Placeholder for a later system similar to \texttt{qa\_system.launch}. This is supposed to be used for complex commands given to the robot.  
        
    \end{itemize}
     
    	
\end{document}
